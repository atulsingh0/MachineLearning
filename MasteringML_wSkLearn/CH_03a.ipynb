{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** DictVectorizer **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "onehot_encoder = DictVectorizer()\n",
    "instances = [\n",
    "    {'city': 'New York'},\n",
    "    {'city': 'San Francisco'},\n",
    "    {'city': 'Chapel Hill'} ]\n",
    "\n",
    "print (onehot_encoder.fit_transform(instances).toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** CountVectorizer **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0 1 0 1 0 1]\n",
      " [1 1 1 0 1 0 1 0]]\n",
      "{'played': 5, 'the': 6, 'duke': 1, 'in': 3, 'lost': 4, 'unc': 7, 'basketball': 0, 'game': 2}\n"
     ]
    }
   ],
   "source": [
    "corpus = [\n",
    "    'UNC played Duke in basketball',\n",
    "    'Duke lost the basketball game'\n",
    "]\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "print (vectorizer.fit_transform(corpus).todense())\n",
    "print (vectorizer.vocabulary_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 0 1 0 0 1 0 0 0 1]\n",
      " [0 1 1 1 0 0 1 0 0 1 0 0]\n",
      " [1 0 0 0 0 1 0 0 1 0 1 0]]\n",
      "{'played': 7, 'lost': 6, 'the': 9, 'duke': 2, 'unc': 11, 'this': 10, 'singh': 8, 'is': 5, 'atul': 0, 'in': 4, 'basketball': 1, 'game': 3}\n"
     ]
    }
   ],
   "source": [
    "# adding one more sentence in corpus\n",
    "\n",
    "corpus = [\n",
    "    'UNC played Duke in basketball',\n",
    "    'Duke lost the basketball game',\n",
    "    'This is Atul Singh'\n",
    "]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "print (vectorizer.fit_transform(corpus).todense())\n",
    "print (vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 & 2 [[ 2.44948974]]\n",
      "2 & 3 [[ 3.]]\n",
      "1 & 3 [[ 3.]]\n"
     ]
    }
   ],
   "source": [
    "# checking the euclidean distance \n",
    "\n",
    "# converting sentence into CountVectorizer\n",
    "counts = vectorizer.fit_transform(corpus).todense()\n",
    "\n",
    "print(\"1 & 2\", euclidean_distances(counts[0], counts[1]))\n",
    "print(\"2 & 3\", euclidean_distances(counts[1], counts[2]))\n",
    "print(\"1 & 3\", euclidean_distances(counts[0], counts[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Stop Word Filtering **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 0 0 1 0 1]\n",
      " [0 1 1 1 1 0 0 0]\n",
      " [1 0 0 0 0 0 1 0]]\n",
      "{'played': 5, 'duke': 2, 'singh': 6, 'lost': 4, 'game': 3, 'unc': 7, 'basketball': 1, 'atul': 0}\n",
      "1 & 2 [[ 2.44948974]]\n",
      "2 & 3 [[ 3.]]\n",
      "1 & 3 [[ 3.]]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')  # added one option which remove the grammer words from corpus\n",
    "print (vectorizer.fit_transform(corpus).todense())\n",
    "print (vectorizer.vocabulary_)\n",
    "\n",
    "print(\"1 & 2\", euclidean_distances(counts[0], counts[1]))\n",
    "print(\"2 & 3\", euclidean_distances(counts[1], counts[2]))\n",
    "print(\"1 & 3\", euclidean_distances(counts[0], counts[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Stemming and Lemmatization **  \n",
    "\n",
    "**Lemmatization** is the process of determining the lemma, or the morphological root, of an inflected word based on its context. Lemmas are the base forms of words that are used to key the word in a dictionary.\n",
    "\n",
    "**Stemming** has a similar goal to lemmatization, but it does not attempt to produce the morphological roots of words. Instead, stemming removes all patterns of characters that appear to be affixes, resulting in a token that is not necessarily a valid word.\n",
    "\n",
    "Lemmatization frequently requires a lexical resource, like WordNet, and the word's part of speech. Stemming \n",
    "algorithms frequently use rules instead of lexical resources to produce stems and can \n",
    "operate on any token, even without its context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 1]\n",
      " [0 1 1 0]]\n",
      "{'sandwich': 2, 'eaten': 1, 'ate': 0, 'sandwiches': 3}\n"
     ]
    }
   ],
   "source": [
    "corpus = [\n",
    "    'He ate the sandwiches',\n",
    "    'Every sandwich was eaten by him'\n",
    "]\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english')  # added one option which remove the grammer words from corpus\n",
    "print (vectorizer.fit_transform(corpus).todense())\n",
    "print (vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
